# <center>Classifica√ß√£o de CIFAR-10 com ResNet18:<br> Uma Implementa√ß√£o em PyTorch 2.0, Lightning e Torchvision</center>

## üìö 1. Introdu√ß√£o

<p style="font-family: 'serif'; font-size: 16px; text-align: justify;">Caro explorador do universo da Intelig√™ncia Artificial, √© com grande entusiasmo que lhe convido a embarcar nesta jornada pelo meu projeto de Reconhecimento de Imagens utilizando a arquitetura ResNet. Este trabalho √© mais do que um simples projeto, √© um marco em minha odisseia profissional e estou ansioso para compartilhar cada detalhe desta aventura com voc√™.</p>

<p style="font-family: 'serif'; font-size: 16px; text-align: justify;">Nesta expedi√ß√£o, navegaremos pelas √°guas das bibliotecas Python Pytorch 2.0, Lightning e Torchvision, ferramentas poderosas que nos auxiliar√£o a construir um modelo de aprendizado profundo para reconhecimento de imagens. Nosso navio √© a arquitetura ResNet, uma verdadeira obra-prima da engenharia de aprendizado de m√°quina, conhecida por sua robustez e efic√°cia em tarefas de vis√£o computacional.</p>

<p style="font-family: 'serif'; font-size: 16px; text-align: justify;">Nosso mapa do tesouro √© o conjunto de dados CIFAR10. Este conjunto √© como uma b√∫ssola para a comunidade de aprendizado de m√°quina, composto por 60.000 imagens coloridas de 32x32 distribu√≠das em 10 classes distintas, cada uma contendo um total de 6.000 imagens. √â neste vasto oceano de dados que treinaremos e avaliaremos nosso modelo.</p>

## üì¶ 2. Instala√ß√£o & Carga de Pacotes 

<div style="background-color: #f0f0f0; padding: 10px; border-radius: 10px; margin: 10px;">
<ol>
    
<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>os</strong>: M√≥dulo Python para intera√ß√£o com o sistema operacional.</p></li>
    
<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>math</strong>: M√≥dulo Python para tarefas matem√°ticas.</p></li>

<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>torch</strong>: Biblioteca de aprendizado de m√°quina, usada para aplica√ß√µes como processamento de linguagem natural.</p></li>
    
<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>pickle</strong>: M√≥dulo Python para serializa√ß√£o e des-serializa√ß√£o de estruturas de objetos Python.</p></li>
    
<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>numpy</strong>: Biblioteca Python para suporte a grandes arrays e matrizes multidimensionais.</p></li>

<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>pandas</strong>: Biblioteca de software para manipula√ß√£o e an√°lise de dados.</p></li>

<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>seaborn</strong>: Biblioteca de visualiza√ß√£o de dados Python baseada em matplotlib.</p></li>

<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>matplotlib</strong>: Biblioteca de plotagem para Python.</p></li>

<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>lightning</strong>: Wrapper leve do PyTorch para pesquisa de IA de alto desempenho.</p></li>

<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>torchvision</strong>: Pacote do PyTorch que consiste em conjuntos de dados populares, arquiteturas de modelos e transforma√ß√µes comuns de imagens para vis√£o computacional.</p></li>
    
<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>torchmetrics</strong>: Biblioteca PyTorch de m√©tricas para modelos de aprendizado de m√°quina e aprendizado profundo.</p></li>
    
<li><p style="font-family: 'serif'; font-size: 16px; text-align: justify;"><strong>pkg_resources</strong>: O m√≥dulo pkg_resources distribu√≠do com setuptools fornece uma API para bibliotecas Python acessarem seus arquivos de recursos, e para aplica√ß√µes e frameworks extens√≠veis descobrirem automaticamente plugins.</p></li>
    
</ol>
</div>
    
## 3. üíª Configura√ß√£o de Ambiente

### 3.1 Reprodutibilidade dos Experimentos

A fun√ß√£o `set_seed` √© usada para definir a semente para geradores de n√∫meros aleat√≥rios no NumPy e PyTorch. Isso √© √∫til para garantir que os experimentos sejam reproduz√≠veis, ou seja, que os mesmos resultados sejam obtidos sempre que o c√≥digo for executado com a mesma semente.

Aqui est√£o as funcionalidades de cada parte do c√≥digo:

- `torch.manual_seed(seed)`: Define a semente para o gerador de n√∫meros aleat√≥rios do PyTorch para a CPU.

- `os.environ['PYTHONHASHSEED'] = str(seed)`: Define a semente para as fun√ß√µes hash do Python

- `if torch.cuda.is_available()`: Verifica se uma GPU est√° dispon√≠vel.

- `torch.cuda.manual_seed_all(seed)`: Define a semente para todas as GPUs dispon√≠veis.

- `torch.backends.cudnn.deterministic = True`: Garante que o backend cuDNN use apenas algoritmos determin√≠sticos.

- `torch.backends.cudnn.benchmark = False`: Desativa o uso de um algoritmo de convolu√ß√£o heur√≠stico.

## 4. üñºÔ∏è Carregamento e Pr√©-processamento de Imagens

- **M√©dia e Desvio Padr√£o:** O objetivo √© criar uma classe Python que calcule a m√©dia e o desvio padr√£o das imagens originais. Esses valores s√£o importantes porque ser√£o usados posteriormente para padronizar as imagens.

- **Cria√ß√£o dos Transformadores:** Ap√≥s calcular a m√©dia e o desvio padr√£o, o pr√≥ximo passo √© criar os transformadores. Estamos utilizando o m√≥dulo `torchvision.transforms` para isso. Os transformadores s√£o usados para aplicar transforma√ß√µes nas imagens, como redimensionamento, recorte, normaliza√ß√£o, etc. Neste caso, estamos utilizando a m√©dia e o desvio padr√£o obtidos na etapa anterior para padronizar as imagens. A padroniza√ß√£o √© uma t√©cnica comum de pr√©-processamento de dados que ajuda a acelerar o treinamento e a converg√™ncia dos modelos de aprendizado de m√°quina.
    
- `Normaliza√ß√£o:` A normaliza√ß√£o √© realizada usando a seguinte f√≥rmula:

$$x^{'} = \frac{x - \bar{x}}{\sigma}$$

- `Cria√ß√£o dos DataLoaders:` Finalmente, criamos os DataLoaders com o conjunto de dados CIFAR-10. Os DataLoaders s√£o usados para carregar os dados em lotes durante o treinamento do modelo. Eles tamb√©m podem embaralhar os dados e aplicar transforma√ß√µes. Neste caso, estamos utilizando o DataLoader para carregar as imagens do CIFAR-10 que foram padronizadas na etapa anterior.

## 5. üß¨ Vis√£o Geral da Arquitetura ResNet


### 5.1 Introdu√ß√£o √† ResNet

A ResNet, ou Rede Residual, √© uma arquitetura de rede neural convolucional que se tornou uma refer√™ncia no campo da vis√£o computacional. Proposta pelos pesquisadores Kaiming He, Xiangyu Zhang, Shaoqing Ren e Jian Sun em 2015, a ResNet introduziu o conceito de "conex√µes residuais", que permitem o treinamento eficaz de redes muito mais profundas do que era poss√≠vel anteriormente.

As redes neurais convolucionais tradicionais tentam aprender representa√ß√µes de n√≠vel superior √† medida que aprofundam a rede, com cada camada tentando aprender algo novo. No entanto, √† medida que essas redes se tornam mais profundas, elas come√ßam a sofrer de um problema conhecido como "desaparecimento do gradiente", onde as camadas mais profundas da rede s√£o incapazes de aprender efetivamente.

A ResNet aborda esse problema atrav√©s de suas conex√µes residuais, que efetivamente permitem que os gradientes sejam retropropagados para camadas mais anteriores. Isso significa que, em vez de tentar aprender uma representa√ß√£o inteiramente nova em cada camada, cada camada na ResNet aprende apenas a diferen√ßa (ou "res√≠duo") entre sua entrada e sa√≠da. Isso permite que a ResNet treine redes significativamente mais profundas, com muitos modelos ResNet tendo centenas ou mesmo milhares de camadas.

Desde a sua introdu√ß√£o, a ResNet tem sido amplamente utilizada em uma variedade de aplica√ß√µes de vis√£o computacional, desde o reconhecimento de imagens at√© a detec√ß√£o de objetos, e continua a ser uma das arquiteturas de rede neural convolucional mais populares e influentes at√© hoje.

### 5.2 Conex√µes Residuais

As conex√µes residuais s√£o a inova√ß√£o central da arquitetura ResNet e s√£o a raz√£o pela qual a ResNet pode treinar redes muito mais profundas do que as arquiteturas anteriores.

Em uma rede neural convencional, cada camada aprende uma nova representa√ß√£o da entrada. No entanto, √† medida que a rede se torna mais profunda, isso pode se tornar um problema. As camadas mais profundas t√™m que aprender representa√ß√µes cada vez mais complexas e, eventualmente, a rede pode sofrer do problema do "desaparecimento do gradiente", onde as camadas mais profundas t√™m dificuldade em aprender.

A ideia por tr√°s das conex√µes residuais √© contornar esse problema. Em vez de cada camada aprender uma nova representa√ß√£o, cada camada em uma ResNet aprende apenas a diferen√ßa, ou "res√≠duo", entre sua entrada e sa√≠da. Isso √© feito adicionando a entrada original diretamente √† sa√≠da da camada (da√≠ o nome "conex√£o residual").

Matematicamente, se a entrada para uma camada √© x e a fun√ß√£o que a camada aprende √© F(x), ent√£o a sa√≠da da camada em uma rede convencional seria $F(x)$. Em uma ResNet, a sa√≠da seria F(x) + x. Isso significa que a fun√ß√£o F(x) n√£o precisa aprender a representa√ß√£o completa; ela s√≥ precisa aprender o res√≠duo.

Essa abordagem simples, mas poderosa, permite que a ResNet treine redes com centenas ou mesmo milhares de camadas, superando o problema do desaparecimento do gradiente.

### 5.3 Blocos Residuais
    
Os blocos residuais s√£o os componentes fundamentais da arquitetura ResNet. Cada bloco residual consiste em uma s√©rie de camadas convolucionais e uma "conex√£o de atalho" que pula essas camadas.

Em um bloco residual, a entrada passa por uma s√©rie de camadas convolucionais, cada uma seguida por uma fun√ß√£o de ativa√ß√£o n√£o linear. No entanto, em vez de passar a sa√≠da dessas camadas diretamente para a pr√≥xima camada, a entrada original √© adicionada √† sa√≠da das camadas convolucionais. Isso √© chamado de "conex√£o de atalho" ou "conex√£o residual".

Matematicamente, se a entrada para o bloco residual √© $x$ e a sa√≠da das camadas convolucionais √© $F(x)$, ent√£o a sa√≠da do bloco residual √© $F(x) + x$. Isso significa que o bloco residual est√° realmente aprendendo a fun√ß√£o $F(x) = y - x$, onde $y$ √© a sa√≠da desejada. Em outras palavras, o bloco residual est√° tentando aprender o "res√≠duo" ou a diferen√ßa entre a entrada e a sa√≠da desejada.

Essa estrutura permite que a ResNet treine redes muito mais profundas do que seria poss√≠vel com redes neurais convencionais. Ao adicionar a entrada original √† sa√≠da das camadas convolucionais, a ResNet pode efetivamente evitar o problema do "desaparecimento do gradiente", onde as camadas mais profundas da rede t√™m dificuldade em aprender devido √† diminui√ß√£o dos gradientes durante a retropropaga√ß√£o.<br>

<center><img src="https://miro.medium.com/v2/resize:fit:1122/1*RTYKpn1Vqr-8zT5fqa8-jA.png"></center>

### 5.4 Profundidade da ResNet

A profundidade de uma rede neural se refere ao n√∫mero de camadas que ela possui. Uma das principais vantagens da ResNet √© a sua capacidade de suportar redes muito mais profundas do que as arquiteturas anteriores.

As redes neurais convencionais tendem a sofrer de um problema conhecido como "desaparecimento do gradiente" √† medida que se tornam mais profundas. Isso ocorre porque, durante o treinamento, os gradientes que s√£o retropropagados para as camadas mais antigas tendem a se tornar muito pequenos. Como resultado, as camadas mais antigas da rede t√™m dificuldade em aprender.

A ResNet aborda esse problema atrav√©s do uso de conex√µes residuais. Ao adicionar a entrada original diretamente √† sa√≠da de cada bloco residual, a ResNet permite que os gradientes sejam retropropagados diretamente atrav√©s da rede. Isso permite que a ResNet treine redes com centenas ou mesmo milhares de camadas.

Existem v√°rias variantes da ResNet, cada uma com um n√∫mero diferente de camadas. Por exemplo, a ResNet-18 tem 18 camadas, a ResNet-34 tem 34 camadas, a ResNet-50 tem 50 camadas, e assim por diante. Em geral, as redes mais profundas s√£o capazes de aprender representa√ß√µes mais complexas, mas tamb√©m s√£o mais dif√≠ceis de treinar e mais propensas a overfitting.

### 5.5 Treinamento da ResNet

O treinamento da ResNet √© semelhante ao de outras redes neurais convolucionais. O processo come√ßa com a inicializa√ß√£o dos pesos da rede, geralmente com pequenos valores aleat√≥rios. Em seguida, a rede √© treinada iterativamente usando um conjunto de dados de treinamento. Em cada itera√ß√£o, a rede faz uma previs√£o com base em sua entrada atual, e essa previs√£o √© comparada com a verdadeira sa√≠da usando uma fun√ß√£o de perda. A fun√ß√£o de perda quantifica o qu√£o longe a previs√£o est√° da verdadeira sa√≠da.

Os gradientes da fun√ß√£o de perda em rela√ß√£o aos pesos da rede s√£o ent√£o calculados usando a retropropaga√ß√£o. Esses gradientes s√£o usados para atualizar os pesos da rede na dire√ß√£o que minimiza a fun√ß√£o de perda. Este processo √© repetido muitas vezes at√© que a rede seja capaz de fazer previs√µes precisas sobre os dados de treinamento.

Um aspecto importante do treinamento da ResNet √© a escolha do otimizador. O otimizador determina como os pesos da rede s√£o atualizados com base nos gradientes calculados. Alguns otimizadores comuns usados no treinamento da ResNet incluem SGD (Stochastic Gradient Descent), Adam e RMSprop.

Al√©m disso, durante o treinamento, v√°rias t√©cnicas de regulariza√ß√£o podem ser usadas para evitar o overfitting. Isso inclui coisas como dropout, weight decay e data augmentation.

### 5.6 Aplica√ß√µes da ResNet

A ResNet tem uma ampla gama de aplica√ß√µes na √°rea de vis√£o computacional, gra√ßas √† sua capacidade de treinar redes profundas e eficientes. Aqui est√£o algumas das principais aplica√ß√µes da ResNet:

- **Reconhecimento de Imagens:** A ResNet √© frequentemente usada para tarefas de reconhecimento de imagens, onde o objetivo √© identificar o objeto principal em uma imagem. Por exemplo, a ResNet pode ser treinada para reconhecer se uma imagem cont√©m um gato ou um cachorro.

- **Detec√ß√£o de Objetos:** A ResNet tamb√©m pode ser usada para detec√ß√£o de objetos, que √© uma tarefa mais complexa que envolve identificar v√°rios objetos em uma imagem e desenhar uma caixa delimitadora ao redor de cada um. Por exemplo, a ResNet pode ser usada para identificar carros, pessoas e sinais de tr√¢nsito em uma imagem de uma cena de rua.

- **Segmenta√ß√£o Sem√¢ntica:** A segmenta√ß√£o sem√¢ntica √© uma tarefa de vis√£o computacional que envolve classificar cada pixel em uma imagem como pertencente a uma determinada classe. A ResNet pode ser adaptada para tarefas de segmenta√ß√£o sem√¢ntica atrav√©s do uso de uma arquitetura de rede totalmente convolucional.

- **Transfer√™ncia de Aprendizado:** A ResNet pr√©-treinada no conjunto de dados ImageNet √© frequentemente usada como ponto de partida para muitas tarefas de vis√£o computacional. O modelo pr√©-treinado pode ser ajustado fino em um novo conjunto de dados com um n√∫mero relativamente pequeno de imagens, permitindo que o modelo se beneficie do aprendizado pr√©vio da ResNet.

## üöÄ 6. Carregando e Treinando o Modelo Pr√©-treinado ResNet

### 6.1 Carregando os Pesos do ResNet-18<br>

Este bloco de c√≥digo define uma fun√ß√£o chamada `load_resnet18` que carrega o modelo ResNet-18 e ajusta suas configura√ß√µes para a tarefa de classifica√ß√£o de imagens no conjunto de dados CIFAR-10.

Aqui est√° uma explica√ß√£o detalhada:

- `model = models.resnet18(pretrained=pretrained)`: Esta linha carrega a arquitetura ResNet-18. Se `pretrained=True`, o modelo √© inicializado com pesos pr√©-treinados no ImageNet.

- `for param in model.parameters(): param.requires_grad = True`: Este loop habilita o ajuste fino de todas as camadas do modelo. Isso significa que os gradientes ser√£o calculados para os par√¢metros do modelo durante o treinamento, permitindo que seus valores sejam atualizados.

- `model.fc = nn.Linear(in_features=512, out_features=10, bias=True)`: Aqui, a √∫ltima camada totalmente conectada do modelo (que originalmente foi projetada para a classifica√ß√£o de 1000 classes no ImageNet) √© substitu√≠da por uma nova camada totalmente conectada para a classifica√ß√£o de 10 classes (o n√∫mero de classes no CIFAR-10).

- `if torch.cuda.is_available(): model = model.cuda()`: Se uma GPU estiver dispon√≠vel, o modelo ser√° movido para a GPU para acelerar os c√°lculos.

- `modelo = load_resnet18(pretrained=True)`: Finalmente, a fun√ß√£o `load_resnet18` √© chamada para carregar o modelo ResNet-18 com pesos pr√©-treinados e retornar o modelo ajustado para a tarefa de classifica√ß√£o do CIFAR-10. O modelo retornado √© armazenado na vari√°vel `modelo`.

### 6.2 Configura√ß√µes de Otimiza√ß√£o<br>

Este bloco de c√≥digo define o otimizador, o agendador e a fun√ß√£o de custo que ser√£o usados para treinar o modelo ResNet-18 no conjunto de dados CIFAR-10. Aqui est√° uma explica√ß√£o detalhada:

- `optimizer = torch.optim.AdamW(modelo.parameters(), lr=0.001, weight_decay=0.01)`: Esta linha define o otimizador como AdamW, que √© uma varia√ß√£o do algoritmo de otimiza√ß√£o Adam que inclui a decaimento de peso (tamb√©m conhecido como regulariza√ß√£o L2). O otimizador AdamW √© conhecido por ter um bom desempenho em tarefas de aprendizado profundo. Os par√¢metros do modelo s√£o passados para o otimizador, juntamente com a taxa de aprendizado (`lr=0.001`) e o fator de decaimento de peso (`weight_decay=0.01`). A f√≥rmula de atualiza√ß√£o do peso no AdamW √© a seguinte:

$$\theta_{t+1, i} = \theta_{t, i} - \eta \left(\frac{1}{\sqrt{\hat{v}_t + \epsilon}} \cdot \hat{m}_t + w_{t, i} \theta_{t, i}\right), \forall t$$

- `scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)`: Esta linha define o agendador de taxa de aprendizado, que ajusta a taxa de aprendizado durante o treinamento. Neste caso, a taxa de aprendizado √© multiplicada por `gamma=0.5` a cada `step_size=10` √©pocas. Isso √© √∫til para reduzir a taxa de aprendizado √† medida que o treinamento progride, o que pode levar a um melhor desempenho do modelo.

- `criterion = nn.CrossEntropyLoss()`: Esta linha define a fun√ß√£o de custo como a perda de entropia cruzada, que √© comumente usada para tarefas de classifica√ß√£o. A perda de entropia cruzada mede a dissimilaridade entre a distribui√ß√£o de probabilidade prevista pelo modelo e a distribui√ß√£o de probabilidade verdadeira dos r√≥tulos. A fun√ß√£o de perda de entropia cruzada (CrossEntropyLoss) √© calculada usando a seguinte f√≥rmula:

$$‚Ñì(x, y) = L = {l_1, ‚Ä¶, l_N}^T, \quad l_n = - w_{y_n} \log \frac{\exp(x_{n, y_n})}{\sum_{c=1}^C \exp(x_{n, c})} \cdot 1_{y_n ‚â† ignore\_index}$$

Na f√≥rmula:

- $‚Ñì(x,y)$ √© a perda total para o minibatch.

- $L$ √© o vetor de perdas individuais para cada observa√ß√£o no minibatch.

- $l_n$ √© a perda para a n-√©sima observa√ß√£o no minibatch.

- $w_{y_n}$ √© o peso associado √† classe verdadeira para a n-√©sima observa√ß√£o.

- $x_{n,y_n}$ √© a pontua√ß√£o de logit para a classe verdadeira da n-√©sima observa√ß√£o.

- O denominador da fra√ß√£o dentro do logaritmo √© a soma das exponenciais das pontua√ß√µes de logit para todas as classes, que √© basicamente a parte do softmax da entropia cruzada.

- $1_{y_n \neq ignore_index}$ √© uma fun√ß√£o indicadora que √© igual a $1$ quando $y_n$ √© diferente do √≠ndice de ignorar (se houver), e $0$ caso contr√°rio.

### 6.3 Treino e Valida√ß√£o do Modelo





